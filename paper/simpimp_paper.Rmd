---
title             : "The role of salience in young children's processing of ad-hoc implicatures"
shorttitle        : "Children's ad-hoc implicature processing"

author: 
  - name          : "Erica J. Yoon"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Department of Psychology, Jordan Hall, 450 Serra Mall (Bldg. 420), Stanford, CA, 94305"
    email         : "ejyoon@stanford.edu"
  - name          : "Michael C. Frank"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Stanford University"

author_note: |
      We would like to acknowledge Asher Kaye, Stephanie Hsiang, and Jacqueline Quirke for their assistance in data collection, and thank the staff and families at Children's Discovery Museum of San Jose and Bing Nursery School.
      All data, analysis code, and experiment files and links and their  preregistration are available at https://github.com/ejyoon/simpimp_rs. 
      This work was supported by a Postgraduate Doctoral Fellowship provided to EJY by Natural Sciences and Engineering Research Council of Canada, NSF #1456077, and Jacobs Advanced Research Fellowship to MCF.
      
abstract: |
  Language comprehension often requires making *implicatures*. For example, inferring that "I ate some of the cookies" implicates the speaker ate some *but not all* (scalar implicatures); and "I ate the chocolate-chip cookies" where there are both chocolate chip cookies and raisin cookies in the context implicates that the speaker ate the chocolate chip, but *not both the chocolate chip and raisin cookies* (ad-hoc implicatures). Children’s ability to make scalar implicatures develops around age five, with ad-hoc implicatures emerging somewhat earlier. In the current work, using a time-sensitive tablet paradigm, we examined developmental gains in children’s ad-hoc implicature processing, and found evidence for successful pragmatic inferences by children as young as 3 years in a supportive context and substantial developmental gains in inference computation from 2 to 5 years. We also tested whether one cause of younger children (2-year-olds)'s consistent failure to make pragmatic inferences is their difficulty in inhibiting an alternative interpretation that is more salient than the target meaning (the *salience hypothesis*). Our findings supported this hypothesis: Younger children’s failures with pragmatic inferences were related to effects of the salience mismatch between possible interpretations. 
 
  
keywords          : "Pragmatics; cognitive development; language processing; implicature; tablet"
wordcount         : "9136"

bibliography      : ["simpimp.bib"]

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes
mask              : no

class             : "man"
output            : papaja::apa6_pdf
---

```{r load_packages, include = FALSE}
library("papaja"); library(xtable); library(tidyverse)
library(langcog)
library(here)
library(ggthemes)
library(brms)
library(lme4)
library(corrr)
library(psych)
```

```{r global_options, include=FALSE}
# rm(list=ls())
knitr::opts_chunk$set(                      echo=FALSE, warning=FALSE, cache=T, message=FALSE, sanitize = T)
```

```{r analysis_preferences}
# Seed for random number generation
set.seed(42)
```

```{r load}
d_sample1_raw <- read.csv(here("data_ana/data","sample1.csv")) %>%
  mutate(sample = "original")

list_info <- read.csv(here("data_ana/data","list_info.csv")) %>%
  distinct(subid, .keep_all=T)

order <- read.csv(here("data_ana/data","trial_info.csv"))

d_sample1_raw <- left_join(d_sample1_raw, list_info) %>%
  left_join(., order)

d_sample1_raw2 <- left_join(d_sample1_raw, order) 

# filter by external criteria
d_sample1_external <- d_sample1_raw2 %>%
  filter(trial_type != "practice",
         age_group != "1",
         age_group != "6",
         english > 3)

# filter by internal (data) criteria
d_sample1_internalDrop <- d_sample1_raw2 %>%
    group_by(subid) %>%
    summarise(nrow=n()) %>%
    filter(nrow < 10) %>%
    droplevels()

d_sample1_final <- d_sample1_external %>%
  filter(!subid %in% d_sample1_internalDrop$subid) %>%
  droplevels()
```

```{r sample2}
d_sample2_raw <- read.csv(here("data_ana/data","sample2.csv")) %>%
  mutate(sample = "replication",
         site = "cdm")

log <- read.csv(here("data_ana/data","log.csv")) %>%
  mutate(English = as.numeric(as.character(fct_recode(English,
                              "10" = "five-ten",
                              "95" = "90-95")))) %>%
  rename(english = English)

order <- read.csv(here("data_ana/data","trial_info.csv"))
```

```{r clean}
d_sample2_raw <- left_join(d_sample2_raw, order) %>%
  left_join(., log) %>%
  distinct(subid, trial_num, .keep_all=T)

d_sample2_external <- d_sample2_raw %>%
  filter(keep_drop == "keep",
         !is.na(keep_drop),
         consent == "Y",
         as.numeric(as.character(english)) > 70,
         age_group %in% c("2", "3", "4"),
         !is.na(age)) %>%
  filter(trial_type != "practice")

d_sample2_internalDrop <- d_sample2_raw %>%
    group_by(subid) %>%
    summarise(nrow=n()) %>%
    filter(nrow < 10) %>%
    droplevels()

d_sample2_final <- d_sample2_external %>%
  filter(!subid %in% d_sample2_internalDrop$subid) %>%
  droplevels()

# check counterbalancing
# d_sample2_final %>%
#   group_by(age_group, list, subid) %>%
#   summarise(number = n()) %>%
#   group_by(age_group, list) %>%
#   summarise(number = n())
```

```{r}
d <- rbind(d_sample1_final,
           d_sample2_final %>%
             select(colnames(d_sample1_final))) %>%
  select(-english) %>%
  mutate(correct = as.numeric(as.character(fct_recode(correct,
                                                      "0" = "N",
                                                      "1" = "Y")))) %>%
  mutate(item_rel = case_when(
    item_num == "1vs1" | item_num == "2vs1" ~ "fewer",
    item_num == "2vs2" | item_num == "3vs1" ~ "more"
  )) %>%
  mutate(age_group = as.numeric(as.character(age_group)))
```

```{r outlier}
top_bound <- mean(log(d$rt)) + 3*sd(log(d$rt))
bottom_bound <- mean(log(d$rt)) - 3*sd(log(d$rt))

rt_filter <- d %>%
  mutate(pass = case_when(
    log(rt) < top_bound & log(rt) > bottom_bound ~ "pass",
    TRUE ~ "fail")) %>%
  group_by(pass) %>%
  summarise(n = n()) %>%
  spread(pass, n) %>%
  mutate(prop_fail = 100*fail/(fail+pass))

d <- d %>%
  filter(log(rt) < top_bound, 
         log(rt) > bottom_bound) %>%
  mutate(subid = factor(subid))

write_csv(d, path = here("data_ana/data","final_analyzed_data.csv"))
```

Language comprehension in context often requires inferring an intended meaning that goes beyond the literal semantics of what a speaker says. Consider a speaker who asserts that:

(1) I ate some of the cookies.

\noindent A reasonable listener could assume from this sentence that the speaker ate some *but not all of the cookies*. Inferences like this one, known as *implicatures*, are commonplace in conversation and provide one important tool for speakers to use language flexibly. They also are related to a broader set of pragmatic phenomena like underspecification [@levinson2000] and politeness [@brown1987]. 

How does the ability to make pragmatic inferences develop in childhood? A general finding is that implicature follows a relatively delayed trajectory, with even school-aged children sometimes struggling with implicature tasks [@noveck2001]. A rich literature has explored both these developmental changes and possible hypotheses about the sources of difficulty for children [e.g., @barner2011; @papafragou2003; @stiller2015]. These investigations are important because they shed light on developmental changes in children's ability to comprehend language in context more broadly, as well as the processing challenges posed by pragmatic language comprehension.

In the current paper, we investigate the developmental trajectory of the processing of one specific type of implicatures, *ad-hoc implicatures*, which tend to be easier for young children than other implicatures that rely on more sophisticated linguistic knowledge [@papafragou2003;@stiller2015;@horowitz2018]. In addition, we test a specific proposal for why young children might find even these inferences challenging, namely that the inferential target is typically less salient than the distractor. In the remainder of the Introduction, before describing our own work we first introduce pragmatic implicature in more depth, then review developmental evidence on implicature.

## Pragmatic Implicature

In @grice1975logic's classic account of pragmatic inference, conversation is a cooperative act. Speakers choose utterances such that the listener can understand the intended message, and listeners in turn interpret these utterances with the assumption of the speaker's cooperativeness in mind. The listener then expects a cooperative speaker to have produced an utterance that is truthful, informative, relevant, and concise, relative to the the present conversational needs. Based on these expectations, the listener can make inferences that go beyond the literal meanings of the speaker's words. The non-literal interpretations computed through these inferential processes are called pragmatic implicatures. 

A concrete example of such an implicature follows from sentence (1), which implicates that the speaker ate some *but not all of the cookies*. This kind of inference is often referred to as a *scalar implicature* because it relies on the fact that "all of the cookies" entails "some of the cookies" as part of a lexical scale [@horn1972]. In contrast, another kind of implicature, *ad-hoc implicature*, is context-based. Uttering: 

(2) I ate the chocolate chip cookies.

\noindent in a context where two kinds of cookies – chocolate chip and raisin – are available, implicates that the speaker ate the chocolate chip *but not both the chocolate chip cookies and raisin cookies*.^[@grice1975logic calls these implicatures generalized (scalar) vs. particularized (ad-hoc), but we use a theory-neutral designation here.] In this case, the context sets up a contrast between the proposition offered ("ate the chocolate chip cookies") and a stronger set of alternatives ("ate [all/both the chocolate chip and the raisin] the cookies") that is determined by the context (and hence is "ad hoc" in the sense of being constructed in this particular situation). 

Implicatures like these have been an important case study for pragmatics more broadly. Notably, different accounts of pragmatic reasoning analyze even the simple examples above in different ways. In the classic Gricean analysis [as elaborated by @levinson1983], the speaker utters *p* ("some of the cookies"), which implicates *q* ("not all of the cookies") in the following way. (A) The speaker is presumed to be cooperative and observing Grice's maxims. (B) To maintain this assumption, the listener must assume that *q* is true; otherwise a maxim will be violated. (In this case the maxim is informativeness, since saying "some of the cookies" if "all of the cookies" were true would be underinformative). (C) The speaker is presumed to believe that it is mutually known by both parties that the listener can work out *q*. 

This analysis -- though influential -- is in fact just one proposal among many, and likely does not map onto either the mental computations carried out by listeners or the specific issues that lead to developmental differences in implicature ability. Both classic theories of communication [e.g., @sperber1986] and more recent probabilistic models of pragmatic inference [e.g., @frank2012; see @goodman2016 for review] describe the processes that language users use to compute such implicatures in different ways. For example, @chierchia2012 give an account of implicature as a specific, grammaticalized operation that involves enriching the meaning of *p* with the negation of all stronger alternatives within a specified alternative set. In contrast, on the probabilistic view, implicatures arise naturally as part of the process of cooperative reasoning by rational agents. 


Our goal here is not to distinguish between these different formalisms; instead, we are interested in understanding the processing of implicature in childhood. Despite that, it is useful to review the probabilistic view as it helps guide some of our predictions below. We consider sentence (2), following the analysis given in @goodman2016. Under the rational speech act (RSA) model, there is a space of meanings (e.g., ATE(chocolate chip & raisin), ATE(chocolate chip), etc.), each of which may have some prior probability of being correct. There is also a space of utterances (e.g., "I ate the chocolate chip cookies," "I ate the cookies"), each of which is either literally consistent or inconsistent with each meaning. Given a particular utterance, a listener can reason probabilistically about the speaker's intended meaning in making this utterance. He can do this by considering that the speaker is a Bayesian agent who chose the appropriate utterance for her intended meaning. He reasons about the speaker making her own choice by considering a listener who is also a Bayesian agent reasoning in this same way. This definition is endlessly recursive, however. In practice, the recursion can be grounded by a speaker considering a "literal listener," who interprets utterances according to their literal truth value [for further formal details, see @goodman2016]. 

In the specific case of (2), the listener's reasoning can be glossed as "if the speaker had wanted to say she ate 'all of the cookies', she could have said just 'cookies'; but she didn't, she said something more specific: 'chocolate chip'; thus she probably intended me to recover the meaning ATE(chocolate chip)." Notice that this reasoning, when explained verbally, actually approximates the standard Gricean logic (though with some differences). Of course, one benefit of the RSA formalism is that probabilities can be put to each of these inferences and so the strength of the interpretive judgment can be predicted [@frank2012]. 
On the other hand, the RSA-style reasoning differs from other implicature accounts that stress the intentionality of the speaker to convey a stronger meaning through the expression of a weaker meaning [e.g., @bach1999] and that hence grant a privileged status to implicatures specifically. In contrast, RSA treats implicature like other general cases of contextual disambiguation. 
 

## The Development of Pragmatic Implicature


A rich psycholinguistic literature has measured adults’ processing of implicatures relative to literal interpretations and has found that adults robustly compute implicatures in a range of contexts, though their processing time can vary depending on the context [@bott2012; @breheny2013; @huang2018; @grodner2010]. How does the ability to make implicatures develop? Since implicature computation is an important indicator of broader pragmatic understanding, many studies have tested children’s abilities on a variety of implicatures.   

Children tend to have the most difficulty with scalar implicatures relying on quantifiers, modals, and other functional elements. For example, in @papafragou2003’s study, a puppet saw three out of three horses jump over a fence, and described the scene infelicitously by saying "Some of the horses jumped over the fence." Adults tend to reject this infelicitous statement, whereas 5-year-old children mostly accept it, suggesting that children failed to compute the relevant scalar implicature [though see @katsos2011, for an alternative explanation]. Besides struggling with *some* vs. *all* [@huang2009b; @hurewitz2006; @noveck2001], children in the same age range have consistently failed to compute implicatures involving scalar contrasts, including *a* vs. *some* [@barner2009], *might* vs. *must* [@noveck2001], and *or* vs. *and* [@chierchia2001].

While children struggle on many scalar implicature tasks, they tend to be more successful at computing ad-hoc implicatures (which depend on context, rather than lexical scales). One potential difficulty in a typical scalar implicature task is the need to generate relevant alternatives to a given scalar term. For children to hear "some of the horses jumped over the fence" and derive the implicature "some *but not all*," they must first realize that "all" is the relevant alternative to "some." @barner2011 argued that children’s failures in scalar implicature tasks are due to their lack of ability to generate the alternative to negate spontaneously upon hearing the term offered. @barner2011’s claim predicts that children’s implicature computation should improve when they can access the relevant alternatives. Consistent with this claim, children can be primed with relevant scalar alternatives, leading to enhanced implicature performance [@skordos2016]. Furthermore, children show substantially improved implicature computation in ad-hoc implicature tasks – which provided access to relevant alternatives in context – compared to scalar implicature tasks [@horowitz2018; @katsos2011; @papafragou2004; @stiller2015]. 

For example, @stiller2015 showed 2.5- to 5-year-old children three different faces: a face with no item; a face with only glasses; and a face with glasses and a top-hat, and asked children to choose one of the three faces as the referent in a puppet’s statement, "My friend has glasses." In this task, the alternative referent (face with glasses and hat) was visible in the context, and thus access to the alternative terms ("glasses and hat") was made easier. In general, we assume that the standard route for referring to these visual properties of the context will be by naming them. The design intention in this study for using simple nouns like "hat" was therefore to make it obvious what the linguistic alternatives would be by virtue of the highly accessible names for stimuli. Children as young as 3.5 years chose the face with only glasses as the referent, suggesting that they successfully computed the implicature that the puppet’s friend has "glasses but not both glasses and hat." Similarly, in one study that tested both scalar and ad-hoc implicature computation, 4-year-olds successfully made ad-hoc implicatures, but performed poorly on scalar implicatures using the same stimuli [@horowitz2018]. 

Despite older children’s success, children below 3 years of age appear to struggle with even simple ad-hoc implicatures. Even in the ad-hoc paradigm described above [@stiller2015], 2.5- and 3-year-olds still did not make the implicature-consistent choice at above-chance levels. Does this finding imply that young toddlers lack pragmatic understanding, specifically an awareness of the need for informativeness in cooperative communication? On the contrary, children are sensitive to informativeness in communication: From age two onward, when they are asked to produce referring expressions, children appear to recognize the level of referential ambiguity of their own expressions and attempt to provide more information through speech and gestures in more ambiguous situations [e.g., instead of "the boy," saying "the boy with the dog"; or naming an object while pointing in cases where the point alone is not precise enough; @matthews2012; @oneill2001]. Hence, a lack of sensitivity to the need for communicative informativeness does not seem to be the problem for toddlers’ implicature processing. So what causes toddlers’ failures in these easier ad-hoc implicature tasks specifically?

## The Current Study


One potential explanation for younger children’s struggle with ad-hoc implicatures is the mismatch in salience between potential interpretations. This explanation is inspired by the RSA framework described above, in the sense that this salience mismatch would be manifest in the pragmatic computation as a higher prior probability of a particular referent. For example, in @stiller2015’s study, a target referent (e.g., face with glasses only) had fewer features than its alternative distractor to be rejected (e.g., face with glasses and hat). The distractor, which had a greater number of nameable features, was more salient both perceptually and conceptually, likely drawing children’s attention more strongly than the target. Under the RSA framework -- and very likely under other pragmatic theories, though perhaps with a less clearly specified prediction -- such a mismatch in prior probabilities would lead to a weaker pragmatic inference.

The mismatch between stimulus salience (prior probability) and the target of the pragmatic inference may be particularly difficult developmentally. From a mechanistic perspective, a task with this kind of competition between targets may be especially challenging to children because their executive function is not yet fully developed [@diamond1996; @davidson2006], and specifically their ability to inhibit responses to salient targets (but see Discussion for further consideration of whether children’s failures should be attributed to their inhibitory control abilities per se). 

Such an issue might be important outside of the specific case of ad-hoc implicature and referent-selection tasks. For example, referent selection tasks may be representative of analogous problems in naturalistic language comprehension for children, in which the goal is often to figure out what referent a speaker is talking about or how to connect a new word to a new referent [in the case of word learning; @frank2014]. And in such situations, there is a body of evidence suggesting that referent salience does in fact influence children's attention [@hollich2000;@yurovsky2017].  

Further, under RSA analysis given above there is no fundamental difference between referent selection tasks and other implicature comprehension tasks. Thus, the asymmetry between correct but weaker target meaning and incorrect but more salient or higher prior probability distractor meaning is present in other types of implicatures too, though less obviously so. For example, scalar implicature is typically described as rejecting the term that yields the "stronger" propositional meaning (e.g., ate "all" of the cookies) and adding its negation to the "weaker" proposition (e.g., "some but not all" of the cookies). Computing a forced-choice scalar implicature thus also requires avoiding the stronger meaning, which typically describes a larger set size. Although the referents in such tasks are not always pictured visually side-by-side, they are in at least some paradigms [e.g., @huang2009b]. At least in these cases -- and perhaps more generally -- the stronger alternative could reasonably be viewed as being more salient or higher prior probability. And, as above, when prior probabilities (whether induced by perceptual factors like salience or emerging from other sources) conflict with pragmatic inferences, the resulting comprehension situation may be especially difficult for children. 

For all of these reasons, in our current work, we were interested in exploring the issue of distractor salience and how it played out in the development of implicature processing for children. For our experiment, we adopted a referent selection method, in which participants were asked to select a referent among a set of candidates. As mentioned earlier, referent selection paradigms have shown evidence of successful implicature computation in youngest children to date [@horowitz2018; @stiller2015], and are analogous to one important aspect of of language comprehension in naturalistic language environments, namely identifying a speaker's intended referent 
(On the other hand, because such paradigms can be solved by RSA-style agents that are not specifically focused on implicating a particular meaning, we are cautious below in interpreting success as evidence of implicature per se. For convenience, however we still, refer to these as ad-hoc implicature *tasks*). 

This setup allowed us to create a systematic manipulation of the stimuli in our referent selection method. Under the RSA model, the more alternative utterances there are to refer to a particular referent, the less likely any one of them is. Thus, adding more features to the distractor referent in the referent selection task should make it even less likely as the referent of any particular one. For example, in the faces case used by @stiller2015, if the target is a face with glasses, then a face with a hat, glasses, and a mustache (three features) should be a *worse* distractor referent for "glasses" than a face with just a hat and glasses (two features). @frank2014 tested this prediction with adults in a word-learning case and found quantitative support for the idea that the number of features was related to the strength of pragmatic judgments. 

The interesting thing about this manipulation, however, is that it might very well have an *opposite* effect on young children because of the referent salience explanation given above. While a distractor with more features should create a stronger pragmatic inference, it should also be more salient to young children, leading to a higher prior probability and worse performance. Thus, in our current experiment we predicted that young children would struggle differentially in the case there were more features on the distractor, while older children would find this case no more difficult and perhaps even easier. 

We stress that, although our manipulation was inspired by the RSA model, it does not depend on that model. As touched on above, there are a variety of different accounts that try to explain exactly what pragmatic inference children are making in ad-hoc implicature tasks. In the @stiller2015 example, "my friend has glasses" can implicate "my friend has glasses *but no hat*" based on the immediate context. A slightly different interpretation could be: "...glasses *but no other distinguishing features*," however [exhaustivity implicature; @groenendijk1985semantics]. For the purposes of the current work, we cannot differentiate between these proposals -- as long as an account incorporated prior information in some fashion, it would likely make a similar prediction. Thus, our goal is not to make a test of a particular implicature account, but rather to test the idea that referent salience (instantiated as prior probability in the RSA model) affects children's implicature behavior. 

In our experiment, we implemented the referent selection task using a tablet paradigm. This methodological change allowed us to examine children’s reaction times for selecting the target referent along with their specific selection [@frank2016]. Compared to previous studies, we also reduced the number of potential referents in context to further simplify the task. In @stiller2015's paradigm, there were three potential referents in the context (face with no item, face with only glasses, face with glasses and hat); in our current paradigm, we presented two instead of three potential referents (e.g. plate with a carrot and plate with a carrot and a banana) to minimize cognitive load for the younger children in our task.

We present data here from two independent samples: The first planned sample of children across four age groups (2-, 3-, 4-, and 5-year-olds) initially showed a pattern consistent with the salience hypothesis, where children were more accurate for trials with lower salience contrasts than for trials with higher salience contrasts. This effect was relatively small, however, and our analysis plan was not prespecified, leading us to worry about the possibility that analytic flexibility might have led us to overestimate our effect [e.g., @simmons2011false]. We thus collected a second, fully preregistered sample of children across the three youngest groups (2-, 3- and 4-year-olds) to replicate this initial finding and make a stronger test of the hypothesis.

# Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

```{r participantsummarytab, echo = F, results = 'asis'}
# total number of participants
d_part1 <-  d %>%
  group_by(sample, age_group, subid) %>%
  summarise(n=n()) %>%
  group_by(sample, age_group) %>%
  summarise(total=n())

#SD
d_part2 <- d %>%
  group_by(sample, age_group, age, subid) %>%
  summarise(n=n()) %>%
  group_by(sample, age_group) %>%
  summarise(Mean = round(mean(age),2),
            SD=round(sd(age),2))

# girls
d_part3 <- d %>%
  group_by(sample, age_group, sex, subid) %>%
  summarise(n=n()) %>%
  group_by(sample, age_group, sex) %>%
  summarise(n=n()) %>%
  spread(sex, n) %>%
  mutate(Girls = round(F/(F+M) * 100,1)) %>%
  select(sample, age_group, Girls)
  
d_table1 <- left_join(d_part1, d_part2) %>%
  left_join(., d_part3) %>%
  mutate(age_group = as.character(age_group),
         total = as.character(total))%>%
  rename(Sample = sample,
         "Age bin" = age_group,
         "Mean (years)" = Mean,
         "SD (years)" = SD,
         "Number of participants" = total,
         "% Girls" = Girls
  )

apa_table(d_table1, caption = "Demographic information of participants in the original and replication samples.")
```

## Participants

In the original sample, either parents and their children visiting Children's Discovery Museum (San Jose, CA), or children in a local nursery school were invited to participate in a tablet study, and a total of 120 children were recruited. Participants were excluded from the sample for the following reasons: age other than 2 to 5 years (*n* = 3); parent-reported English exposure less than our prespecified criterion of 75% (*n* = 5); parental interference (*n* = 2); and noncompliance or difficulty with the experimental procedure (*n* = 9). After excluding participants who completed fewer than the prespecified number of 10 trials (*n* = 2), the final sample consisted of 99 children (see Table \@ref(tab:participantsummarytab)). 

In the replication sample, a total of 116 children were recruited, all at Children's Discovery Museum in San Jose. Reasons for exclusions were: age other than 2 to 4 years (*n* = 11); parent-reported English exposure less than our prespecified criterion of 75% (*n* = 15); parental interference (*n* = 3); noncompliance or difficulty with the experimental procedure (*n* = 3); and technical error (*n* = 4). The final sample consisted of 80 children (no participant was excluded for completing fewer than 10 trials). 
It should be noted that we deviated from our preregistered sample since we did not recruit 5-year-olds, as we saw 4-year-olds already performing at ceiling and thus considered 4-year-olds to suffice as the oldest group. 

## Stimuli and Design

```{r stimuli, fig.cap="Trial types. Green box indicates the target referent for each trial given the utterance at the bottom."}
knitr::include_graphics("figs/stimuli.png", dpi = 170)
```

On each trial, participants saw two images: a target and distractor, which could either be an item with a single feature (e.g. a lunchbox with only an apple), or an item with double features (e.g., a lunchbox with an apple and an orange). In each trial, a pre-recorded voice said a sentence (e.g., "Look at these lunchboxes. Elmo's lunchbox has an apple."). After participants chose the object that was being referred to, a green box appeared around the chosen object to show that the choice had been made. For each trial, we recorded the participant’s accuracy, or whether he or she selected the correct target referent, and reaction time, or time spent between naming of the referent ("...an *apple*") and the participant’s referent selection.

There were three types of test trials (shown at the top of each panel in Figure \@ref(fig:stimuli)). In *implicature* trials, the target item had a single feature (e.g., an apple), and the distractor item had two or three features (see below for the manipulation of number of features) -- one that was in common with the target (e.g., an apple) and the other feature(s) that was/were unique (e.g., an orange). The test sentence named the feature that was common to the target and distractor. Thus, if participants understood that "Elmo's lunchbox has an apple" implicates "Elmo's lunchbox has an apple *but not an orange*" in the given context, it was predicted that they would choose the target more often than the distractor; otherwise, if they did not make implicatures, they would choose the two at equal rates (or even choose the distractor more often depending on the degree of saliency contrast -- see below).

There were two additional trial types, with semantically unambiguous targets: *Control-double* trials looked identical to implicature trials, but the target and distractor were switched, such that the double-feature item was the target and the single-feature item was the distractor, and the test sentence named the unique feature on the target. *Control-single* trials presented two items that each had a unique single feature, and either could be the target. Children saw 4 implicature, 4 control-double, and 8 control-single trials; adults saw 6 implicature, 6 control-double, and 12 control-single trials. 

Each trial type was further divided by the number of features present on the target and distractor (shown on the right side of Figure \@ref(fig:stimuli)): Within implicature trials, *fewer-feature* (2-vs-1) trials presented two features (an apple and an orange) on the distractor and one feature (an apple) on the target, whereas *more-feature* (3-vs-1) trials presented three features (an apple, an orange, and a cookie) on the distractor and one feature on the target; Within control-double trials, *fewer-feature* (2-vs-1) trials presented two features (an apple and an orange) on the target and one feature (an apple) on the distractor, whereas *more-feature* (3-vs-1) trials presented three features (an apple, an orange, and a cookie) on the distractor and one feature on the target; Lastly, within control-single trials, *fewer-feature* (1-vs-1) trials presented one feature each on the distractor and the target, whereas *more-feature* (2-vs-2) trials presented two features each on the distractor and on the target. 

We hypothesized that older children would choose the target more often in the more-feature implicature trials than the fewer-feature implicature trials because implicatures are strengthened more in more-feature trials -- "Elmo's lunchbox has an apple" is more likely to mean "apple only" given an orange AND cookie on the alternative referent, thus more things that could have been named but were not.  On the contrary, younger children were predicted to choose the target less often in the more-feature trials than the fewer-feature trials because the distractor is more salient in the fewer-feature trials, while still being consistent with the literal meaning.

There were six sets of item and feature types, and the features were named with nouns found on the  MacArthur-Bates Communicative Development Inventory word list [@fenson1994]. Two orders of the test trials were created, such that trial types and item types were counterbalanced and trial order was pseudo-randomized across the two orders.

## Procedure

An experimenter introduced children to the task as a game on a tablet. Then they completed two practice trials, where they were asked to select an obvious, unambiguous referent (e.g., "cow" as opposed to "rabbit"), followed by 16 test trials. 

## Data analysis
We used `r cite_r("simpimp.bib")` for all our analyses.

# Results

We were interested in children’s processing of implicatures in comparison to unambiguous utterances, and developmental gains across ages. We used two different measures: (1) accuracy and (2) reaction time for choosing the correct referent. For each measure, we asked: (a) do children show developmental gains in selection of the target referent? And (b) does children’s performance vary depending on salience contrast? That is, when there are a relatively greater number of features on the distractor, do children have more difficulty and are they slower in choosing the correct referent? 

As per our standard operating procedures, we removed trials in which the log of reaction time was more than 3 standard deviations above or below the mean (upper bound: `r exp(top_bound)/1000` seconds; lower bound: `r exp(bottom_bound)/1000` second; percentage of data excluded: `r rt_filter$prop_fail` %). Throughout this section, we used Bayesian linear mixed-effects models [`brms` package in R; @R-brms] using crossed random effects of participant and item with the maximal random effects structure supported by the design [@gelman2006data; @barr2013random]. Age is plotted in year bins, but was analyzed as a continuous variable, scaled and centered, in our statistical model. 

```{r accuracy, fig.cap="Proportion of 2- to 5-year-old children selecting the target in the original and replication samples (rows) in different trial types (columns). Data are binned into 6-month age groups for visualization purposes (all analyses are conducted on continuous data). Lines are loess smoothing functions. Solid lines represent trials in which there were fewer features present (2-vs-1 for control-double and implicature, 1-vs-1 for control-single) and dashed lines represent trials with more features (3-vs-1 for control-double and implicature, 2-vs-2 for control-single). Error bars are 95% confidence intervals, and are placed at the mean of the age bin and offset slightly to avoid overplotting. Dotted line represents a conservative chance level at 50\\%."}
d_acc_ms <- d %>%
  mutate(sample = as.factor(sample)) %>%
  group_by(sample, age_group, trial_type, item_rel, subid) %>%
  summarise(correct = mean(correct))


d_acc <- d_acc_ms %>%
  group_by(sample, age_group, trial_type, item_rel) %>%
  multi_boot_standard(col = "correct") %>%
  mutate(correct = mean) %>%
  select(-mean) %>%
  ungroup() %>%
  left_join(d_acc_ms %>%
              group_by(sample, age_group, trial_type, item_rel) %>%
              summarise(n = n()))

    

ggplot(d_acc %>%
         mutate(trial_type = fct_recode(trial_type,
                                        "control-single" = "control_single",
                                        "control-double" = "control_double",
                                        "implicature" = "inference"),
                age_group = as.numeric(as.character(age_group))+.5), 
       aes(x = age_group, y = correct,
           group = item_rel, linetype = item_rel)) + 
  geom_smooth(col="grey40", span= 2, aes(weight = n), se = FALSE, size=.7) + 
  # geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
  #              position = position_dodge(width = .1)) + 
  geom_linerange(aes(x = age_group, ymin = ci_lower, ymax = ci_upper, 
                     group = item_rel), inherit.aes = T,
                 color = "black", alpha = 0.7, size = .7,
                 position = position_dodge(width = 0.15)) +
  # scale_color_grey(end = 0.4)+
  facet_grid(sample ~ trial_type, labeller = labeller(sample = label_both)) +
  geom_hline(yintercept=.50,lty="dotted", alpha=.5) +
  ylab("Accuracy") +
  xlab("Age (years)") +
  ylim(c(0, 1)) +
  xlim(c(2, 5.8)) +
  theme_few() +
  # scale_color_solarized() +
  guides(linetype=guide_legend(title="Number of features"),
         size = guide_legend(title="Number of participants"),
         col=FALSE) +
    theme(legend.position="bottom",
        text = element_text(size=14))
```

```{r ttest}
ms <- d %>%
  group_by(sample, age_group, trial_type, item_rel, subid) %>%
  summarize(correct = mean(correct, na.rm=TRUE))

ttest.acc.2y.sample1 = t.test(filter(ms, age_group == "2" & trial_type == "inference" & sample == "original")$correct, mu=.5)
ttest.acc.2y.sample2 = t.test(filter(ms, age_group == "2" & trial_type == "inference" & sample == "replication")$correct, mu=.5)
ttest.acc.3y.sample1 = t.test(filter(ms, age_group == "3" & trial_type == "inference" & sample == "original")$correct, mu=.5)
ttest.acc.3y.sample2 = t.test(filter(ms, age_group == "3" & trial_type == "inference" & sample == "replication")$correct, mu=.5)
ttest.acc.4y.sample1 = t.test(filter(ms, age_group == "4" & trial_type == "inference" & sample == "original")$correct, mu=.5)
ttest.acc.4y.sample2 = t.test(filter(ms, age_group == "4" & trial_type == "inference" & sample == "replication")$correct, mu=.5)
ttest.acc.5y.sample1 = t.test(filter(ms, age_group == "5" & trial_type == "inference" & sample == "original")$correct, mu=.5)
```

```{r ttest2}
ttest.acc.2y.fewer.sample1 = t.test(filter(ms, age_group == "2" & trial_type == "inference" & item_rel == "fewer" & sample == "original")$correct, mu=.5)
ttest.acc.2y.more.sample1 = t.test(filter(ms, age_group == "2" & trial_type == "inference" & item_rel == "more" & sample == "original")$correct, mu=.5)
ttest.acc.2y.fewer.sample2 = t.test(filter(ms, age_group == "2" & trial_type == "inference" & item_rel == "fewer" & sample == "replication")$correct, mu=.5)
ttest.acc.2y.more.sample2 = t.test(filter(ms, age_group == "2" & trial_type == "inference" & item_rel == "more" & sample == "replication")$correct, mu=.5)
```

## Accuracy

```{r brmaccSample1, echo = F, results = 'asis'}
load(here("data_ana", "simpimp_brms_acc_sample1.Rds"))

acc.tab.sample1 <- as.data.frame(summary(brms_acc_orig)$fixed) %>%
  select(Estimate, Est.Error, 'l-95% CI', 'u-95% CI') %>%
  rename(Mean = Estimate,
         "SD" = Est.Error,
         "95% CI-Lower" = 'l-95% CI',
         "95% CI-Upper" = 'u-95% CI'
         )

acc.tab.sample1$Predictor <- c("Intercept",
                      "Age",
                      "Control-double",
                      "Implicature",
                      "More features",
                      "Control-double * Age",
                      "Implicature * Age",
                      "More features * Age",
                      "Control-double * More features",
                      "Implicature * More features",
                      "Control-double * Age * More features",
                      "Implicature * Age * More features"
                      )
rownames(acc.tab.sample1) <- NULL
acc.tab.sample1 <- acc.tab.sample1[,c(5,1:4)]

apa_table(acc.tab.sample1, caption= "Predictor mean estimates with standard deviation and 95% credible interval information for a Bayesian linear mixed-effects model predicting accurate selection of target for the original sample.")
```

```{r brmaccSample2, echo = F, results = 'asis'}
load(here("data_ana", "simpimp_brms_acc_sample2.Rds"))

acc.tab.sample2 <- as.data.frame(summary(brms_acc_rep)$fixed) %>%
  select(Estimate, Est.Error, 'l-95% CI', 'u-95% CI') %>%
  rename(Mean = Estimate,
         "SD" = Est.Error,
         "95% CI-Lower" = 'l-95% CI',
         "95% CI-Upper" = 'u-95% CI'
         )

acc.tab.sample2$Predictor <- c("Intercept",
                      "Age",
                      "Control-double",
                      "Implicature",
                      "More features",
                      "Control-double * Age",
                      "Implicature * Age",
                      "More features * Age",
                      "Control-double * More features",
                      "Implicature * More features",
                      "Control-double * Age * More features",
                      "Implicature * Age * More features"
                      )
rownames(acc.tab.sample2) <- NULL
acc.tab.sample2 <- acc.tab.sample2[,c(5,1:4)]

apa_table(acc.tab.sample2, caption= "Predictor mean estimates with standard deviation and 95% credible interval information for a Bayesian linear mixed-effects model predicting accurate selection of target for the replication sample.")
```

```{r brmacc, echo = F, results = 'asis'}
load(here("data_ana", "simpimp_brms_acc_both_sample.Rds"))

acc.tab <- as.data.frame(summary(brms_acc)$fixed) %>%
  select(Estimate, Est.Error, 'l-95% CI', 'u-95% CI') %>%
  rename(Mean = Estimate,
         "SD" = Est.Error,
         "95% CI-Lower" = 'l-95% CI',
         "95% CI-Upper" = 'u-95% CI'
         )

acc.tab$Predictor <- c("Intercept",
                       "Sample",
                      "Age",
                      "Control-double",
                      "Implicature",
                      "More features",
                      "Control-double * Age",
                      "Implicature * Age",
                      "More features * Age",
                      "Control-double * More features",
                      "Implicature * More features",
                      "Control-double * Age * More features",
                      "Implicature * Age * More features"
                      )
rownames(acc.tab) <- NULL
acc.tab <- acc.tab[,c(5,1:4)]

apa_table(acc.tab, caption= "Predictor mean estimates with standard deviation and 95% credible interval information for a Bayesian linear mixed-effects model predicting accurate selection of target in both the original and replication samples.")
```

The analysis of the accuracy rate (Figure \@ref(fig:accuracy)) showed that children across all ages were able to identify the target in control trials, indicating that, as expected, they can readily compute unambiguous meanings. In implicature trials, 4- and 5-year-olds’ performances were nearly at ceiling, replicating the previous results [@stiller2015; @horowitz2018]. In our paradigm, even 3-year-olds chose the inferential target above chance^[Because our task is a two-alternative forced choice, we define chance to be 50% across all trials. This baseline is a standard comparison that reflects the possibility that a child was completely inattentive to the task and chose completely at random. This baseline is more conservative than a salience-based baseline, which would likely suggest that the correct (inferentially-consistent) target would be chosen less than 50% of the time (e.g., the "mumble" condition in Stiller et al., 2015).] (original sample: $t$(`r ttest.acc.3y.sample1$parameter`) = `r round(ttest.acc.3y.sample1$statistic, 2)`, $p$ < 0.001; replication sample: $t$(`r ttest.acc.3y.sample2$parameter`) = `r round(ttest.acc.3y.sample2$statistic, 2)`, $p$ < 0.001). On the other hand, 2-year-olds’ performance in implicature trials did not differ from chance overall, but their performance varied depending on the number of features present. In 3-vs-1 trials (i.e., with a relatively greater number of features on the distractor), 2-year-olds did not choose the correct target referent, and even tended to choose the distractor somewhat more often numerically (original sample: $t$(`r ttest.acc.2y.more.sample1$parameter`) = `r round(ttest.acc.2y.more.sample1$statistic, 2)`, $p$ = `r round(ttest.acc.2y.more.sample1$p.value, 3)`; replication sample: $t$(`r ttest.acc.2y.more.sample2$parameter`) = `r round(ttest.acc.2y.more.sample2$statistic, 2)`, $p$ = `r round(ttest.acc.2y.more.sample2$p.value, 3)`). However, In 2-vs-1 trials (with fewer features on the distractor), 2-year-olds tended to choose the target more often than the distractor. This difference was numerically present in both samples and statistically significant in one (original sample: $t$(`r ttest.acc.2y.fewer.sample1$parameter`) = `r round(ttest.acc.2y.fewer.sample1$statistic, 2)`, $p$ = `r round(ttest.acc.2y.fewer.sample1$p.value, 3)`; replication sample: $t$(`r ttest.acc.2y.fewer.sample2$parameter`) = `r round(ttest.acc.2y.fewer.sample2$statistic, 2)`, $p$ = `r round(ttest.acc.2y.fewer.sample2$p.value, 3)`). By 4 years, this difference in accuracy rate between 2-vs-1 and 3-vs-1 trials was not present.

Bayesian linear mixed models predicting accuracy based on age, trial type and number of features (salience contrast; more-feature vs. fewer-feature) were conducted separately on the original sample and replication sample (Table \@ref(tab:brmaccSample1) and Table \@ref(tab:brmaccSample2)). Both models showed a main effect of age and a main effect of implicature trials, which indicated that children performed more poorly on implicature trials than control trials, while their overall performance on all trial types improved with age. 
In addition, the model for the replication sample showed a two-way negative interaction between age and implicature trials, which suggested that improvement with age for implicature trials was lower compared to control trials for the replication sample. 

We ran an exploratory Bayesian linear mixed-effects model on combined datasets from the original and replication sample, predicting accuracy based on age, trial type and number of features, which showed a three-way positive interaction of age, implicature trials, and number of features (Table \@ref(tab:brmacc)). Unlike control trials, in which children’s performances did not differ by salience contrast, implicature trials showed lower accuracy in 3-vs-1 than 2-vs-1 trials in younger children, but not in older children. Thus, this result supports our hypothesis that the salience contrast between conditions led to greater difficulty with the implicature task for for younger children. 

## Reaction time

```{r rt, fig.cap="Reaction time to select the correct target referent. Conventions are identical to Figure 2."}
d_rt_ms <- d %>%
  mutate(sample = as.factor(sample),
         age_group_small = as.numeric(as.character(cut(age, seq(2,6,.5), 
                                          labels = seq(2,5.5,.5)+.25)))) %>%
  group_by(sample, age_group, trial_type, item_rel, subid) %>%
  summarise(rt = mean(rt))


d_rt <- d_rt_ms %>%
  group_by(sample, age_group, trial_type, item_rel) %>%
  multi_boot_standard(col = "rt") %>%
  mutate(rt = mean) %>%
  select(-mean) %>%
  ungroup() %>%
  left_join(d_acc_ms %>%
              group_by(sample, age_group, trial_type, item_rel) %>%
              summarise(n = n()))

ggplot(d_rt %>%
                  mutate(trial_type = fct_recode(trial_type,
                                        "control-single" = "control_single",
                                        "control-double" = "control_double",
                                        "implicature" = "inference")), 
 aes(x = age_group, y = rt, 
                  group = item_rel, linetype = item_rel)) + 
  geom_smooth(col="grey40", span= 2, aes(weight = n), se = FALSE, size = .7) + 
  # geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), 
  #              position = position_dodge(width = .1)) + 
  geom_linerange(aes(x = age_group, ymin = ci_lower, ymax = ci_upper, 
                     group = item_rel), inherit.aes = T,
                 color = "black", alpha = 0.7, size = .7,
                 position = position_dodge(width = 0.15)) +
  # scale_alpha_discrete(range = c(0.4, 0.8)) +
  # scale_color_grey(end = 0.4)+
  facet_grid(sample ~ trial_type, labeller = labeller(sample = label_both)) +
  ylab("Reaction time (s)") +
  xlab("Age (years)") +
  theme_few() +
  # scale_color_solarized() +
    guides(linetype=guide_legend(title="Number of features"),
         size = guide_legend(title="Number of participants"),
         col = FALSE)+
  theme(text = element_text(size=14),
        legend.position="bottom",
        legend.key = element_rect(colour = "transparent", fill = "white"))
```

```{r brmrtSample1, echo = F, results = 'asis'}
load(here("data_ana", "simpimp_brms_rt_sample1.Rds"))

rt.tab.sample1 <- as.data.frame(summary(brms_rt_sample1)$fixed) %>%
  select(Estimate, Est.Error, 'l-95% CI', 'u-95% CI') %>%
  rename(Mean = Estimate,
         "SD" = Est.Error,
         "95% CI-Lower" = 'l-95% CI',
         "95% CI-Upper" = 'u-95% CI'
         )

rt.tab.sample1$Predictor <- c("Intercept",
                      "Age",
                      "Control-double",
                      "Implicature",
                      "More features",
                      "Control-double * Age",
                      "Implicature * Age",
                      "More features * Age",
                      "Control-double * More features",
                      "Implicature * More features",
                      "Control-double * Age * More features",
                      "Implicature * Age * More features"
                      )
rownames(rt.tab.sample1) <- NULL
rt.tab.sample1 <- rt.tab.sample1[,c(5,1:4)]

apa_table(rt.tab.sample1, caption = "Predictor mean estimates with standard deviation and 95% credible interval information for a Bayesian linear mixed-effects model predicting log reaction time to select the target for the original sample.")
```

```{r brmrtSample2, echo = F, results = 'asis'}
load(here("data_ana", "simpimp_brms_rt_sample2.Rds"))

rt.tab.sample2 <- as.data.frame(summary(brms_rt_sample2)$fixed) %>%
  select(Estimate, Est.Error, 'l-95% CI', 'u-95% CI') %>%
  rename(Mean = Estimate,
         "SD" = Est.Error,
         "95% CI-Lower" = 'l-95% CI',
         "95% CI-Upper" = 'u-95% CI'
         )

rt.tab.sample2$Predictor <- c("Intercept",
                      "Age",
                      "Control-double",
                      "Implicature",
                      "More features",
                      "Control-double * Age",
                      "Implicature * Age",
                      "More features * Age",
                      "Control-double * More features",
                      "Implicature * More features",
                      "Control-double * Age * More features",
                      "Implicature * Age * More features"
                      )
rownames(rt.tab.sample2) <- NULL
rt.tab.sample2 <- rt.tab.sample2[,c(5,1:4)]

apa_table(rt.tab.sample2, caption = "Predictor mean estimates with standard deviation and 95% credible interval information for a Bayesian linear mixed-effects model predicting log reaction time to select the target for the replication sample.")
```

```{r brmrt, echo = F, results = 'asis'}
load(here("data_ana", "simpimp_brms_rt_both_sample.Rds"))

rt.tab <- as.data.frame(summary(brms_rt)$fixed) %>%
  select(Estimate, Est.Error, 'l-95% CI', 'u-95% CI') %>%
  rename(Mean = Estimate,
         "SD" = Est.Error,
         "95% CI-Lower" = 'l-95% CI',
         "95% CI-Upper" = 'u-95% CI'
         )

rt.tab$Predictor <- c("Intercept",
                      "Sample",
                      "Age",
                      "Control-double",
                      "Implicature",
                      "More features",
                      "Control-double * Age",
                      "Implicature * Age",
                      "More features * Age",
                      "Control-double * More features",
                      "Implicature * More features",
                      "Control-double * Age * More features",
                      "Implicature * Age * More features"
                      )
rownames(rt.tab) <- NULL
rt.tab <- rt.tab[,c(5,1:4)]

apa_table(rt.tab, caption = "Predictor mean estimates with standard deviation and 95% credible interval information for a Bayesian linear mixed-effects model predicting log reaction time to select the target in both the original and replication samples.")
```

With increasing age, children computed both implicatures and unambiguous meanings and identified the target faster (Figure \@ref(fig:rt)). Bayesian linear mixed-effects models predicting reaction time based on age, trial type and number of features were conducted separately in the original sample and replication sample, and showed a positive two-way interaction between age and implicature trial (Table \@ref(tab:brmrtSample1) and Table \@ref(tab:brmrtSample2)), indicating that reaction time on implicature trials did not improve with age as much as the speed of processing unambiguous meanings. This interaction was also shown in an exploratory Bayesian linear mixed-effects model on the combined datasets with both samples (Table \@ref(tab:brmrt)). Together with the accuracy finding, this result suggests that though children become proficient at determining the *correct* target referents for ad-hoc implicatures by 5 years, implicature processing develops relatively more slowly. 

In two of the three models (the model on the replication sample only and the model on both datasets together), we also observed a positive two-way interaction between control-double trials and number of features, indicating that children took longer to identify the target in control-double trials with more features than in control-single trials with more features. 

There was no interaction between inference trials and number of features, or between inference trial, age and number of features, however. Why would this be? We did not have a pre-specified hypothesis regarding this pattern of data, but we speculate that once a feature is named (e.g., Elmo’s lunchbox has an apple), it is relatively easier to find the feature in an inferential target image than in the distractor image. The target feature is by itself in the target referent, whereas it is grouped with with other features in the distractor. Thus, the inference trials may allow easy perceptual access to the target feature but also competition with the overall perceptual salience of the distractor. These factors might cancel one another out and lead to undifferentiated reaction times and hence the lack of reaction time interactions. The potential advantage of identifying a feature when it is by itself is only speculative, however, and should be examined further in future work.  

## Reliability 

```{r compute_alpha_acc, echo = F, results='hide'}
# make data frame to compute alpha
d_alpha <- d %>%
  filter(trial_type != "inference") %>%
  mutate(trial_num = as.numeric(as.character(trial_num)) - 2) %>%
  select(subid, age_group, trial_num, correct) %>%
  group_by(age_group, subid) %>%
  arrange(subid, trial_num) %>%
  mutate(trial_order = str_c("t",as.character(1:length(trial_num))),
         n = length(trial_num)) %>%
  select(-trial_num) %>%
  spread(trial_order, correct) %>%
  ungroup()
  # select(-n, -subid, -age_group) %>%
  # alpha(.) %>%
  # summary(.)

d_alpha_mean <- d_alpha %>%
  group_by(age_group) %>%
  summarise(n = mean(n)) %>%
  mutate(age_group = as.factor(age_group))

d_alpha_2y <- d_alpha %>%
  filter(age_group == "2") %>%
  select(-subid, -age_group, -n) %>%
  alpha(.) %>%
  summary(.) %>%
  select(raw_alpha, std.alpha) %>%
  mutate(age_group = "2")

d_alpha_3y <- d_alpha %>%
  filter(age_group == "3") %>%
 select(-subid, -age_group, -n, -t12) %>%
  alpha(.) %>%
  summary(.) %>%
  select(raw_alpha, std.alpha) %>%
  mutate(age_group = "3")

d_alpha_4y <- d_alpha %>%
  filter(age_group == "4") %>%
  select(-subid, -age_group, -n) %>%
  alpha(.) %>%
  summary(.) %>%
  select(raw_alpha, std.alpha) %>%
  mutate(age_group = "4")

d_alpha_5y <- d_alpha %>%
  filter(age_group == "5") %>%
  select(-subid, -age_group, -n) %>%
  alpha(.) %>%
  summary(.) %>%
  select(raw_alpha, std.alpha) %>%
  mutate(age_group = "5")

d_alpha_summary <- rbind(d_alpha_2y, d_alpha_3y, d_alpha_4y, d_alpha_5y) %>%
  left_join(d_alpha_mean, .) %>%
  rename(acc_raw_alpha = raw_alpha, acc_std_alpha = std.alpha)


```

```{r compute_alpha_rt, echo = F, results='hide'}
# make data frame to compute alpha
d_alpha_rt <- d %>%
  filter(trial_type != "inference") %>%
  mutate(trial_num = as.numeric(as.character(trial_num)) - 2) %>%
  select(subid, age_group, trial_num, rt) %>%
  group_by(age_group, subid) %>%
  arrange(subid, trial_num) %>%
  mutate(trial_order = str_c("t",as.character(1:length(trial_num))),
         n = length(trial_num)) %>%
  select(-trial_num) %>%
  spread(trial_order, rt) %>%
  ungroup()
  # select(-n, -subid, -age_group) %>%
  # alpha(.) %>%
  # summary(.)

d_alpha_mean_rt <- d_alpha_rt %>%
  group_by(age_group) %>%
  summarise(n = mean(n)) %>%
  mutate(age_group = as.factor(age_group))

d_alpha_rt_2y <- d_alpha_rt %>%
  filter(age_group == "2") %>%
  select(-subid, -age_group, -n) %>%
  alpha(.) %>%
  summary(.) %>%
  select(raw_alpha, std.alpha) %>%
  mutate(age_group = "2")

d_alpha_rt_3y <- d_alpha_rt %>%
  filter(age_group == "3") %>%
  select(-subid, -age_group, -n) %>% # dropped t12 because of missing values
  alpha(.) %>%
  summary(.) %>%
  select(raw_alpha, std.alpha) %>%
  mutate(age_group = "3")

d_alpha_rt_4y <- d_alpha_rt %>%
  filter(age_group == "4") %>%
  select(-subid, -age_group, -n) %>%
  alpha(.) %>%
  summary(.) %>%
  select(raw_alpha, std.alpha) %>%
  mutate(age_group = "4")

d_alpha_rt_5y <- d_alpha_rt %>%
  filter(age_group == "5") %>%
  select(-subid, -age_group, -n) %>%
  alpha(.) %>%
  summary(.) %>%
  select(raw_alpha, std.alpha) %>%
  mutate(age_group = "5")

d_alpha_rt_summary <- rbind(d_alpha_rt_2y, d_alpha_rt_3y, d_alpha_rt_4y, d_alpha_rt_5y) %>%
  left_join(d_alpha_mean_rt, .) %>%
  rename(rt_raw_alpha = raw_alpha, rt_std_alpha = std.alpha)


```

```{r alphaTable, echo = F, results = 'asis'}
d_alpha_all_summary <- left_join(d_alpha_summary, d_alpha_rt_summary)

alpha.tab <- as.data.frame(d_alpha_all_summary) %>%
  select(-acc_std_alpha, -rt_std_alpha)

colnames(alpha.tab) <- c("Age bin", "$M$ trials", "$\\alpha_{acc}$", "$\\alpha_{rt}$")

apa_table(alpha.tab, escape=FALSE, caption = "Standardized reliability coefficients (Cronbach\'s $\\alpha$) for accuracy (acc) and reaction time (RT) by age group, along with the mean number of trials for each.")
```

As specified in our preregistered protocol, we measured Cronbach’s alpha, a statistic that determines the internal consistency of experimental items [@santos1999cronbach]. We selected the 12 control trials and computed a reliability coefficient for each age group, for both RTs and accuracies. Reliabilities are shown in Table \@ref(tab:alphaTable). Reliabilities for 2-, 3- year olds and adults were reasonable ( > .7). reliabilities for accuracy were lower amongst 4- and 5-year olds due to ceiling effects; for 4-year-olds, reaction time still showed high reliability. For 5-year-olds, neither RT nor accuracy were reliable, likely indicating that this paradigm was simply too easy for them [replicating results from @frank2016].

# Discussion

In our experiment, we confirmed 3- to 5-year-old children’s successes on pragmatic inferences, and saw substantial developmental gains in their accuracy and speed. 4- and 5-year-old children successfully computed pragmatic inferences and identified the inferential targets, consistent with previous findings. We found evidence of successful pragmatic inferences even in 3-year-olds. Further, between 2 and 5 years, there was a clear improvement in processing skills with increasing age, such that correct referent identification was more accurate and faster across both control and implicature trials. Thus, these findings add to the existing literature to attest to children’s growing proficiency in pragmatic processing. 

We also investigated the salience hypothesis, namely that one cause of young children’s struggle with pragmatic inferences stems from their difficulty to inhibit choosing the more salient distractor. In earlier work, there was some numerical suggestion of 2-year-olds’ preference for the more salient but pragmatically incorrect distractor [@stiller2015]. Inspired by this pattern and following the predictions of the RSA model of pragmatic inference, we predicted that increasing the salience of this distractor would result in decreased performance for younger children while increasing performance for older children. The first part of this prediction was clearly supported in our data, with younger children performing worse when the distractor was more salient, with more mixed support for the second part.

In particular, although we observed numerical hints of a gain in accuracy for older children in one sample, we did not see a consistent facilitation effect due to our manipulation. We suspect this finding is due to a ceiling effect: Referent selection via ad-hoc implicature is relatively trivial for four-year-olds [see also @horowitz2018]. However, we saw a possible age-related advantage of pragmatic strengthening in the speed of computation: Whereas younger children tended to be slower in trials with a greater number of features for both unambiguous and inferential meanings, older children began to close the gap and become faster to compute implicatures given increased distractor saliency.

Our findings here support the idea that salience-related competition plays a role in young children's difficulties with ad-hoc implicature tasks. Our salience account is most manifest in the kind of simple referent selection tasks we used here. Despite this, following the general mapping of perceptual salience to prior probabilities in the RSA framework more broadly, we speculate that the account may apply more broadly to implicature computation beyond the scope of these tasks. Any pragmatic implicature requires an asymmetry in the "strength" of the alternatives. In ad-hoc referent-selection contexts, the stronger (more salient) alternative is the item with more features. In scalar implicatures, the implicature that you ate *some but not all of the cookies* is only possible because there is a stronger alternative ("all"). It remains an open empirical question whether the salience mismatch account -- perhaps relabeled as a prior probability mismatch -- might explain some aspects of children’s difficulty with these other cases of implicatures as well. 

The salience hypothesis we tested here relates to broader methodological issues in experiments for young children with both visual and verbal alternative responses. One example of such a bias is the tendency of 2-year-olds to show a bias toward "yes" compared to "no" in answering questions. This bias disappears with age [@fritzley2003young], and there is some evidence that it is related to children's verbal ability and inhibitory control [@moriguchi2008young]. In general, as work on pragmatic inference begins to examine younger children's abilities, it is important to take into consideration a range of cognitive factors in task design. 

Following this line of reasoning, one further potential application of our account is to word learning contexts, where children’s learning of a novel word is facilitated when the target referent is more (not less) salient than its alternative. For example, @frank2014 used an analogous pragmatic inference paradigm in a word learning context: Participants heard a novel label (e.g., "a dinosaur with a *dax*") used to describe an object with two features (a dinosaur with a hat and a bandanna) in the presence of another dinosaur that had one but not the other of the features (a dinosaur with a hat only). 3- and 4-year-olds performed quite well in mapping the novel label to the unique feature, even though in many respects this task should be more, not less, difficult than ad-hoc implicature. One reason for this success might be that the novel label was being mapped to the more, rather than less, salient object.  

Similarly, in classic "mutual exclusivity" paradigms [@markman1988children], by around 18 months, participants succeed in mapping a novel label to a novel object [@halberda2003development]. While the mechanisms underlying this empirical phenomenon are complex, it is well-established that the salience of the novel target is an important factor in children’s success [see @markman2003use for discussion]. Overall, evidence for children’s pragmatic word learning emerges earlier than implicature computation: Children succeed in these tasks substantially at earlier ages than even in our simplified implicature paradigm. We might speculate that one reason for this asymmetry is because implicature tasks require selecting the *less* salient alternative while word learning tasks typically ask participants to select a *more* salient alternative. 

Our findings help in the construction of a comprehensive developmental account of processing of implicatures, and pragmatic inferences in general. In the samples that have been studied in this literature, by 2 years of age, children begin to be aware that informativeness is important to communication.  By 3 to 4 years, the ability to inhibit these salient targets is more developed, and they start to compute ad-hoc implicatures when relevant alternatives to the speaker’s words are provided in context. Scalar implicature performance develops more slowly, however, as children's ability to access the relevant inferential alternatives is only beginning to emerge in the period from 4 to 6 [@barner2011;@skordos2016;@horowitz2018]; their performance during these ages is highly variable and dependent on the nature of the context and its pragmatic demands [@papafragou2004]. 

As illustrated by this timeline, the salience hypothesis we tested is not mutually exclusive with other accounts of children's difficulties in implicature. For example, the "alternatives hypothesis" [@barner2011] is independently supported by a variety of experiments [@horowitz2018;@skordos2016]. Indeed, both the salience and alternatives hypotheses are likely true and likely contribute to children’s difficulty with implicatures to different degrees in different tasks and at different ages. 

One important challenge for this viewpoint is the nature of the ability that children use to overcome the pull of the salient alternative. One possible naive mapping for the ability would be to the broader construct of executive function, which undergoes substantial developmental changes during this period [@davidson2006; @diamond1996]. But executive function is a multi-faceted construct [@miyake2000unity], and the particular components that would be expected to predict visual (and perhaps conceptual) disengagement with a particular referent is unclear. Our own studies attempting to probe individual difference correlations between executive function and implicature ability in development have not been successful [e.g., @horowitz2018;@nordmeyer2016]. Thus, a target for future work is to better characterize the particular cognitive changes that relate to the developmental effects we have observed here. 

There are several further limitations of our work here. First, our salience manipulation involved manipulation of the number of features present on an item, which might have caused a potential confound between salience and processing time. For example, children’s greater looking to the distractor (and thus greater processing time) might have been caused by a real desire to acquire more information, rather than the mere perceptual salience of the distractors. 
Second, as noted in the Introduction, our study does not differentiate between different theoretical proposals about how pragmatic inference is being computed in the current task. 
However, we believe that we are addressing development of implicatures in general,
with a caveat that our definition of implicatures does pertain to broader inferential reasoning between speakers and listeners, rather than having a special status or mechanism as assumed under particular formalisms.
Third, as with nearly all work in the literature on implicature processing, we address the performance of only relatively high socioeconomic status children in a Western context. In our ongoing work we address the generalizability of our task to other developmental contexts [@fortierunderrev]. 

In sum, our work shows evidence that from at least 3 years, children are able to compute ad-hoc implicatures, and that younger children's failures with implicatures on an referent-choosing task are confounded by the salience mismatch between possible referents. This pattern is consistent with a broader generalization, namely that tasks that have typically been used to look at children’s implicature processing have a variety of extraneous processing demands, which may explain why it has been difficult to see children’s underlying pragmatic abilities in such paradigms. Thus, our work demonstrates the importance of using a range of methods to measure children’s pragmatic processing.

\newpage

# References
```{r create_r-references}
r_refs(file = "simpimp.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
